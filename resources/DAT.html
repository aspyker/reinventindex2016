<a>










<div id="session_8076" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=8076" class="openInPopup">

            <span class="abbreviation">DAT201 - </span>

            <span class="title">Cross-Region Replication with Amazon DynamoDB Streams

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>


        <span class="abstract">Under Armour implemented&nbsp;cross-region replication with&nbsp;Amazon DynamoDB Streams.&nbsp;Come listen as they share the keys to success.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_8084" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=8084" class="openInPopup">

            <span class="abbreviation">DAT202 - </span>

            <span class="title">Migrating Your Data Warehouse to Amazon Redshift



					</span>
        </a>


        <span class="abstract">Amazon Redshift is a fast, simple, cost-effective data warehousing solution, and in this session, we look at the tools and techniques you can use to migrate your existing data warehouse to Amazon Redshift. We will then present a case study on Scholastic&rsquo;s migration to Amazon Redshift. Scholastic, a large 100-year-old publishing company, was running their business with older, on-premise, data warehousing and analytics solutions, which could not keep up with business needs and were expensive. Scholastic also needed to include new capabilities like streaming data and real time analytics. Scholastic migrated to Amazon Redshift, and achieved agility and faster time to insight while dramatically reducing costs. In this session, Scholastic will discuss how they achieved this, including options considered, technical architecture implemented, results, and lessons learned.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_11562" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=11562" class="openInPopup">

            <span class="abbreviation">DAT202-R - </span>

            <span class="title">[REPEAT] Migrating Your Data Warehouse to Amazon Redshift

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>

					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">Amazon Redshift is a fast, simple, cost-effective data warehousing solution, and in this session, we look at the tools and techniques you can use to migrate your existing data warehouse to Amazon Redshift. We will then present a case study on Scholastic&rsquo;s migration to Amazon Redshift. Scholastic, a large 100-year-old publishing company, was running their business with older, on-premise, data warehousing and analytics solutions, which could not keep up with business needs and were expensive. Scholastic also needed to include new capabilities like streaming data and real time analytics. Scholastic migrated to Amazon Redshift, and achieved agility and faster time to insight while dramatically reducing costs. In this session, Scholastic will discuss how they achieved this, including options considered, technical architecture implemented, results, and lessons learned.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_10497" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=10497" class="openInPopup">

            <span class="abbreviation">DAT203 - </span>

            <span class="title">Getting Started with Amazon Aurora

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">Amazon Aurora is a MySQL-compatible relational database engine with the speed, reliability, and availability of high-end commercial databases at one-tenth the cost. This session introduces you to Amazon Aurora, explores the capabilities and features of Aurora, explains common use cases, and helps you get started with Aurora. Debanjan Saha, general manager for Aurora, explains how Aurora differs from other commonly available databases while staying compatible with MySQL and providing a high-end, cost-effective alternative to commercial and open-source database engines. In addition, Linda Xu, data architect at Ticketmaster, walks you through Ticketmaster's journey to Amazon Aurora, starting with evaluation through production migration of a critical Ticketmaster database to Amazon Aurora. Ticketmaster is one of the world's top 10 e-commerce companies and the global market leader in ticketing. In this session, Linda discusses how Aurora lets Ticketmaster provide better services to their fans, customers, and clients, and helps reduce the cost and operational burden while giving greater flexibility to support heavy traffic spikes.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9961" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9961" class="openInPopup">

            <span class="abbreviation">DAT204 - </span>

            <span class="title">How Thermo Fisher Is Reducing Mass Spectrometry Experiment Times from Days to Minutes with MongoDB & AWS

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">Mass spectrometry is the gold standard for determining chemical compositions, with spectrometers often measuring the mass of a compound down to a single electron. This level of granularity produces an enormous amount of hierarchical data that doesn't fit well into rows and columns. In this talk, learn how Thermo Fisher is using MongoDB Atlas on AWS to allow their users to get near real-time insights from mass spectrometry experiments&mdash;a process that used to take days. We also share how the underlying database service used by Thermo Fisher was built on AWS.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_10349" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=10349" class="openInPopup">

            <span class="abbreviation">DAT205 - </span>

            <span class="title">Relational and NoSQL Databases on AWS: NBC, MarkLogic, and FileMaker Perspectives on Data Management for Enterprise & Consumer Apps

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">Learn how the AWS Marketplace brings together customers who have challenges with ISVs who have solutions to those challenges. See how to use relational and NoSQL technologies on AWS to build enterprise and consumer apps. NBC used MarkLogic to deliver an award-winning app that can handle high traffic levels and unexpected usage spikes. NBC&rsquo;s popular, Emmy-winning, &ldquo;SNL 40&rdquo;&nbsp;was launched to celebrate the 40th anniversary of Saturday Night Live, and delivers four decades of sketches and performances. Hosted on AWS, the app &mdash; as well as a browser-based platform &mdash; are powered by the MarkLogic Enterprise NoSQL database.&nbsp; Come learn from the team who collaborated on this project how to run your own database on AWS, and how to integrate with Amazon RDS and other data stores.&nbsp;A world-recognized automotive brand needed to deliver real-time response about their worldwide fleet vehicles. You will learn how they used a combination of AWS services and FileMaker Cloud, (an Apple subsidiary, procured through AWS Marketplace) to deliver high-scale dealer-facing applications.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9946" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9946" class="openInPopup">

            <span class="abbreviation">DAT206 - </span>

            <span class="title">NEW LAUNCH! Introducing PostgreSQL compatibility for Amazon Aurora


						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">After we launched Amazon Aurora, a cloud-native relational database with region-wide durability, high availability, fast failover, up to 15 read replicas, and up to five times the performance of MySQL, many of you asked us whether we could deliver the same features - but with PostgreSQL compatibility. We are now delivering a preview of Amazon Aurora with this functionality: we have built a PostgreSQL-compatible edition of Amazon Aurora, sharing the core Amazon Aurora innovations with the object-oriented capabilities, language interfaces, JSON compatibility, ANSI:SQL:2008 compliance, and broad functional richness of PostgreSQL. Amazon Aurora will provide full PostgreSQL compatibility&nbsp;while delivering more than twice the performance of the community PostgreSQL database on many workloads. At this session, we will be discussing the newest addition to Amazon Aurora in detail.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_12256" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=12256" class="openInPopup">

            <span class="abbreviation">DAT206-R - </span>

            <span class="title">[REPEAT] NEW LAUNCH! Introducing Amazon Aurora PostgreSQL-Compatible Edition

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>

					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">After we launched Amazon Aurora, a cloud-native relational database with region-wide durability, high availability, fast failover, up to 15 read replicas, and up to five times the performance of MySQL, many of you asked us whether we could deliver the same features - but with PostgreSQL compatibility. We are now delivering a preview of Amazon Aurora with this functionality: we have built a PostgreSQL-compatible edition of Amazon Aurora, sharing the core Amazon Aurora innovations with the object-oriented capabilities, language interfaces, JSON compatibility, ANSI:SQL:2008 compliance, and broad functional richness of PostgreSQL. Amazon Aurora will provide full PostgreSQL compatibility&nbsp;while delivering more than twice the performance of the community PostgreSQL database on many workloads. At this session, we will be discussing the newest addition to Amazon Aurora in detail.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_11786" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=11786" class="openInPopup">

            <span class="abbreviation">DAT207 - </span>

            <span class="title">How Citus Enables Scalable PostgreSQL on AWS

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">Join the principal engineer of Citus Cloud for a brief overview of Citus, best use cases for it, and a drill down into how it's run and managed as a hosted service on top of AWS. The orchestration of Citus is homegrown, but comes from years of experience of running millions of PostgreSQL databases on top of AWS. Even if you aren't looking to leverage Citus to help you scale out, in this session you'll gain insights applicable to running and managing your stateful services on top of AWS. Citus is a PostgreSQL extension that transforms the database into a distributed, horizontally scalable database. Companies like Cloudflare use Citus to process 40 TB per day. With Citus MX, applications can take advantage of every node in the cluster for writes and yielding near-linear write scaling. Citus MX provide up to 500,000 durable writes per second.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9736" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9736" class="openInPopup">

            <span class="abbreviation">DAT208 - </span>

            <span class="title">Capturing Windows of Opportunity: Real-Time Analytics for Less Than $1000?

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>

					</span>
        </a>


        <span class="abstract">For many organizations, capturing a window of opportunity is their differentiator in the market. They invest in real-time systems to understand and respond to events. With so many use cases, it can be challenging for people to know how to invest in the right platform, and how to build in a cost-optimized way. In this session, we look at how some AWS customers are using real-time analytics to capture windows of opportunity: a telco with a major promotion, an advertising retargeter with global demands, and a personal IOT provider with a lifestyle solution. We dig deeper into their architecture and look for common patterns that can be used to build a real-time analytics platform in a cost-optimized way. We even see how a light-load, real-time analytics system can be built for less than $1000.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_8062" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=8062" class="openInPopup">

            <span class="abbreviation">DAT301 - </span>

            <span class="title">Amazon Aurora Best Practices: Getting the Best Out of Your Databases

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>


        <span class="abstract">Amazon Aurora is a fully managed relational database engine that provides&nbsp;higher performance, availability and durability than previously possible using conventional monolithic database architectures.&nbsp;&nbsp;After launching a year ago, we continued adding many new features and capabilities to Aurora. In this session AWS Aurora experts will discuss the best practices that will help you put&nbsp;these capabilities to the&nbsp;best use. You will also hear from Amazon Aurora customer Intercom on the best practices they adopted for moving live databases with over two billion rows to a new datastore in Amazon Aurora with almost no downtime or lost records.

Intercom was founded to provide a fundamentally new way for Internet businesses to communicate with customers at scale.&nbsp;For growing startups like Intercom, it&rsquo;s natural for the load on datastores to grow on a weekly basis. The usual solution&nbsp;to this problem is to&nbsp;get a bigger box from AWS. But very soon you reach a point where&nbsp;bigger boat is not an option anymore.&nbsp; You will learn about the benefits of moving to such a datastore, the problems it introduced, and all about the new ability for scaling that was not there before.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_8061" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=8061" class="openInPopup">

            <span class="abbreviation">DAT302 - </span>

            <span class="title">Best Practices for Migrating from Commercial Database Engines to Amazon Aurora or PostgreSQL

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>

					</span>
        </a>


        <span class="abstract">You can significantly reduce database licensing and operational costs by migrating from commercial database engines to Amazon Aurora or Amazon RDS for PostgreSQL. In addition to cost reduction you also gain flexibility and operational efficiency by avoiding the frustrating usage constraints that the commercial databases licenses come with. Amazon Aurora and Amazon RDS for PostgreSQL are fully managed database services so you no longer need to worry about complex database management tasks. You can launch a single database instance or thousands of them in just a few minutes, and pay only for what you use. In this session we will dive deep into how AWS Database Migration Service and AWS Schema Conversion Tool help you migrate your commercial databases like Oracle and Microsoft SQL Server to Amazon Aurora or Amazon RDS for PostgreSQL easily and securely with minimal downtime.

In this session you will also learn from Aaron Carerras, Senior Data Architect at FINRA, the approach FINRA has used to migrate their databases to Amazon RDS for PostgreSQL. As a financial regulator, FINRA has strict uptime SLAs and data security requirements and will be using RDS to meet them. The Financial Industry Regulatory Authority (FINRA) is one of the largest independent securities regulators in the United States, tracking up to 75 billion stock market events per day.&nbsp;

&nbsp;</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_7981" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=7981" class="openInPopup">

            <span class="abbreviation">DAT303 - </span>

            <span class="title">Deep Dive on Amazon Aurora

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>


        <span class="abstract">Amazon Aurora is a fully managed relational database engine that combines the speed and availability of high-end commercial databases with the simplicity and cost-effectiveness of open source databases. It is purpose-built for the cloud using a new architectural model and distributed systems techniques to provide far higher performance, availability and durability than previously possible using conventional monolithic database architectures. Amazon Aurora packs a lot of innovations in the engine and storage layers. In this session, we will do a deep-dive into some of the key innovations behind Amazon Aurora, new improvements to Aurora's performance, availability and cost-effectiveness and discuss best practices and optimal configurations.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_8079" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=8079" class="openInPopup">

            <span class="abbreviation">DAT304 - </span>

            <span class="title">Deep Dive on Amazon DynamoDB

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>


        <span class="abstract">Explore Amazon DynamoDB capabilities and benefits in detail and learn how to get the most out of your DynamoDB database. We go over best practices for schema design with DynamoDB across multiple use cases, including gaming, AdTech, IoT, and others. We explore designing efficient indexes, scanning, and querying, and go into detail on a number of recently released features, including JSON document support, DynamoDB Streams, and more. We also provide lessons learned from operating DynamoDB at scale, including provisioning DynamoDB for IoT.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_10929" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=10929" class="openInPopup">

            <span class="abbreviation">DAT304-R - </span>

            <span class="title">[REPEAT] Deep Dive on Amazon DynamoDB



					</span>
        </a>


        <span class="abstract">Explore Amazon DynamoDB capabilities and benefits in detail and learn how to get the most out of your DynamoDB database. We go over best practices for schema design with DynamoDB across multiple use cases, including gaming, AdTech, IoT, and others. We explore designing efficient indexes, scanning, and querying, and go into detail on a number of recently released features, including JSON document support, DynamoDB Streams, and more. We also provide lessons learned from operating DynamoDB at scale, including provisioning DynamoDB for IoT.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_8074" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=8074" class="openInPopup">

            <span class="abbreviation">DAT305 - </span>

            <span class="title">Deep Dive on Amazon Relational Database Service

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>


        <span class="abstract">Amazon RDS allows customers to launch an optimally configured, secure and highly available database with just a few clicks. It provides cost-efficient and resizable capacity while managing time-consuming database administration tasks, freeing you up to focus on your applications and business. Amazon RDS provides you six database engines to choose from, including Amazon Aurora, Oracle, Microsoft SQL Server, PostgreSQL, MySQL and MariaDB. In this session, we take a closer look at the capabilities of RDS and all the different options available. We do a deep dive into how RDS works and&nbsp;the best practises to achive the optimal perfomance, flexibility, and cost saving for your databases.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_10838" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=10838" class="openInPopup">

            <span class="abbreviation">DAT305-R - </span>

            <span class="title">[REPEAT] Deep Dive on Amazon Relational Database Service



					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">Amazon RDS allows customers to launch an optimally configured, secure and highly available database with just a few clicks. It provides cost-efficient and resizable capacity while managing time-consuming database administration tasks, freeing you up to focus on your applications and business. Amazon RDS provides you six database engines to choose from, including Amazon Aurora, Oracle, Microsoft SQL Server, PostgreSQL, MySQL and MariaDB. In this session, we take a closer look at the capabilities of RDS and all the different options available. We do a deep dive into how RDS works and the best practises to achive the optimal perfomance, flexibility, and cost saving for your databases.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9112" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9112" class="openInPopup">

            <span class="abbreviation">DAT306 - </span>

            <span class="title">ElastiCache Deep Dive: Best Practices and Usage Patterns

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>


        <span class="abstract">In this session, we provide a peek behind the scenes to learn about Amazon ElastiCache's design and architecture. See common design patterns with our Redis and Memcached offerings and how customers have used them for in-memory operations to reduce latency and improve application throughput. During this session, we review ElastiCache best practices, design patterns, and anti-patterns.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_8063" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=8063" class="openInPopup">

            <span class="abbreviation">DAT307 - </span>

            <span class="title">Introduction to Managed Database Services on AWS

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>

					</span>
        </a>


        <span class="abstract">Which database is best suited for your use case? Should you choose a relational database or NoSQL or a data warehouse for your workload? Would a managed service like Amazon RDS, Amazon DynamoDB, or Amazon Redshift work better for you, or would it be better to run your own database on Amazon EC2? FanDuel has been running its fantasy sports service on Amazon Web Services (AWS) since 2012. You will learn best practices and insights from FanDuel&rsquo;s successful migrations from self-managed databases on EC2 to fully-managed database services.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_8751" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=8751" class="openInPopup">

            <span class="abbreviation">DAT308 - </span>

            <span class="title">Fireside chat with Groupon, Intuit, and LifeLock on solving Big Data database challenges with Redis

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>


        <span class="abstract">Redis Labs' CMO is hosting a fireside chat with leaders from multiple industries including Groupon (e-commerce ), Intuit (Finance ), and LifeLock (Identity Protection ). This conversation-style session will cover the Big Data related challenges faced by these leading companies as they scale their applications, ensure high availability, serve the best user experience at lowest latencies, and optimize between cloud and on-premises operations. &nbsp;The introductory level session will appeal to both developer and DevOps functions. They will hear about diverse use cases such as recommendations engine, hybrid transactions and analytics operations, and time-series data analysis. The audience will learn how the Redis in-memory database platform addresses the above use cases with its multi-model capability and in a cost effective manner to meet the needs of the next generation applications.&nbsp;Session sponsored by Redis Labs.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9773" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9773" class="openInPopup">

            <span class="abbreviation">DAT309 - </span>

            <span class="title">How Fulfillment by Amazon (FBA) and Scopely Improved Results and Reduced Costs with a Serverless Architecture

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>


        <span class="abstract">We&rsquo;ll share an overview of leveraging serverless architectures to support high performance data intensive applications. Fulfillment by Amazon (FBA) built the Seller Inventory Authority Platform (IAP) using Amazon DynamoDB Streams, AWS Lambda functions, Amazon Elasticsearch Service, and Amazon Redshift to improve results and reduce costs.&nbsp; Scopely will share how they used a flexible logging system built on Kinesis, Lambda, and Amazon Elasticsearch to provide high-fidelity reporting on hotkeys in Memcached and DynamoDB, and drastically reduce the incidence of hotkeys. Both&nbsp;of these customers are&nbsp;using&nbsp;managed services and serverless architecture to build scalable systems that can meet the projected business growth without a corresponding increase in operational costs.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9732" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9732" class="openInPopup">

            <span class="abbreviation">DAT310 - </span>

            <span class="title">Building Real-Time Campaign Analytics Using AWS Services

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>

					</span>
        </a>


        <span class="abstract">Quantcast provides its advertising clients the ability to run targeted ad campaigns reaching millions of online users. The real-time bidding for campaigns runs on thousands of machines across the world. When Quantcast wanted to collect and analyze campaign metrics in real-time, they turned to AWS to rapidly build a scalable, resilient, and extensible framework. Quantcast used Amazon Kinesis streams to stage data, Amazon EC2 instances to shuffle and aggregate the data, and Amazon DynamoDB and Amazon ElastiCache for building scalable time-series databases. With Elastic Load Balancing and Auto Scaling groups, they are able to set up distributed microservices with minimal operation overhead. This session discusses their use case, how they architected the application with AWS technologies integrated with their existing home-grown stack, and the lessons they learned.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9740" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9740" class="openInPopup">

            <span class="abbreviation">DAT311 - </span>

            <span class="title">How Toyota Racing Development Makes Racing Decisions in Real Time with AWS

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>


        <span class="abstract">Toyota Racing Development (TRD) developed a robust and highly performant real-time data analysis tool for professional racing. In this talk, learn how we structured a reliable, maintainable, decoupled architecture built around Amazon DynamoDB as both a streaming mechanism and a long-term persistent data store. In racing, milliseconds matter and even moments of downtime can cost a race. You'll see how we used DynamoDB together with Amazon Kinesis and Kinesis Firehose to build a real-time streaming data analysis tool for competitive racing.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9776" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9776" class="openInPopup">

            <span class="abbreviation">DAT312 - </span>

            <span class="title">How DataXu scaled its Attribution System to handle billions of events per day with Amazon DynamoDB

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>


        <span class="abstract">&ldquo;Attribution&quot; is the marketing term of art for allocating full or partial credit to individual advertisements that eventually lead to a purchase, sign up, download, or other desired consumer interaction. We'll share how we use DynamoDB at the core of our attribution system to store terabytes of advertising history data. The system is cost effective and dynamically scales from 0 to 300K requests per second on demand with predictable performance and low operational overhead.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9735" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9735" class="openInPopup">

            <span class="abbreviation">DAT313 - </span>

            <span class="title">6 Million New Registrations in 30 Days: How the Chick-fil-A One App Scaled with AWS

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>


        <span class="abstract">Chris leads the team providing back-end services for the massively popular Chick-fil-A One mobile app that launched in June 2016. Chick-fil-A follows AWS best practices for web services and leverages numerous AWS services, including Elastic Beanstalk, DynamoDB, Lambda, and Amazon S3. This was the largest technology-dependent promotion in Chick-fil-A history. To ensure their architecture would perform at unknown and massive scale, Chris worked with AWS Support through an AWS Infrastructure Event Management (IEM) engagement and leaned on automated operations to enable load testing before launch.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9775" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9775" class="openInPopup">

            <span class="abbreviation">DAT315 - </span>

            <span class="title">Streaming ETL for RDS and DynamoDB

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>


        <span class="abstract">During this session Greg Brandt and Liyin Tang, Data Infrastructure engineers from Airbnb, will discuss the design and architecture of Airbnb's streaming ETL infrastructure, which exports data from RDS for MySQL and DynamoDB into Airbnb's data warehouse, using a system called SpinalTap. We will also discuss how we leverage Spark Streaming to compute derived data from tracking topics and/or database tables, and HBase to provide immediate data access and generate cleanly time-partitioned Hive tables.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9962" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9962" class="openInPopup">

            <span class="abbreviation">DAT316 - </span>

            <span class="title">How Telltale Games migrated its story analytics from Apache CouchDB to Amazon DynamoDB

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">Every choice made in Telltale Games titles influences how your character develops and how the world responds to you. With millions of users making thousands of choices in a single episode, Telltale Games tracks this data and leverages it to build more relevant stories in real time as the season is developed.&nbsp;In this session, you&rsquo;ll learn about Telltale Games&rsquo; migration from Apache CouchDB to Amazon DynamoDB, the challenges of adjusting capacity to handling spikes in database activity, and how it streamlined its analytics storage to provide new perspectives of player interaction to improve its games.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9960" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9960" class="openInPopup">

            <span class="abbreviation">DAT317 - </span>

            <span class="title">Learn how IFTTT uses ElastiCache for Redis to predict events and index terabytes of logs

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">IFTTT is a free service that empowers people to do more with the services they love, from automating simple tasks to transforming how someone interacts with and controls their home. IFTTT uses ElastiCache for Redis to store transaction run history and schedule predictions as well as indexes for log documents on S3. Join this session to learn how the scripting power of Lua and the data types of Redis allowed them to accomplish something they would not have been able to elsewhere.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_9774" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=9774" class="openInPopup">

            <span class="abbreviation">DAT318 - </span>

            <span class="title">Migrating from RDBMS to NoSQL: How PlayStationâ„¢Network Moved from MySQL to Amazon DynamoDB

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>
						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">In this session, you will learn the key differences between a relational database management service (RDBMS) and non-relational (NoSQL) databases like Amazon DynamoDB. You will learn about suitable and unsuitable use cases for NoSQL databases. You'll learn strategies for migrating from an RDBMS to DynamoDB through a 5-phase, iterative approach. See how Sony migrated an on-premises MySQL database to the cloud with Amazon DynamoDB, and see the results of this migration.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_10555" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=10555" class="openInPopup">

            <span class="abbreviation">DAT320 - </span>

            <span class="title">AWS Database State of the Union

						<i class="fa fa-youtube-play sessionPhoto" aria-hidden="true"></i>

					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">Raju Gulabani, vice president of AWS Database Services (AWS), discusses the evolution of database services on AWS and the new database services and features we launched this year, and shares our vision for continued innovation in this space. We are witnessing an unprecedented growth in the amount of data collected, in many different shapes and forms. Storage, management, and analysis of this data requires database services that scale and perform in ways not possible before. AWS offers a collection of such database and other data services like Amazon Aurora, Amazon DynamoDB, Amazon RDS, Amazon Redshift, Amazon ElastiCache, Amazon Kinesis, and Amazon EMR to process, store, manage, and analyze data. In this session, we provide an overview of AWS database services and discuss how our customers are using these services today.</span>


        <small class="length">1 Hour</small>


        <small class="type">Breakout Session</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_10495" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=10495" class="openInPopup">

            <span class="abbreviation">DAT321 - </span>

            <span class="title">Workshop: Using the Database Migration Service (DMS) for Database Consolidation, Data Distribution and Replication


						<i class="fa fa-picture-o sessionVideo" aria-hidden="true"></i>
					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">It can help you do much more. You can use DMS to consolidate multiple databases into a single database or split a single database into multiple databases. You can also use DMS for data distribution to multiple systems. For both of these use cases your source database can be outside of AWS (on premises) or in AWS (EC2 or RDS). DMS can also be used for near real-time replication of data. Replication can be done to one or more targets within AWS, in the same region or across regions. You can also replicate data from databases within AWS to databases outside of AWS. In this session we will discuss all these usage patterns and help you try them out yourselves.

Prerequisites:

You should have good database knowledge and at least some experience with Amazon RDS or Amazon Aurora.

Participants should have an AWS account established and available for use during the workshop.

Please bring your own laptop.</span>


        <small class="length">2.5 hours</small>


        <small class="type">Workshop</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_10494" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=10494" class="openInPopup">

            <span class="abbreviation">DAT322 - </span>

            <span class="title">Workshop: Stretching Scalability: Doing more with Amazon Aurora



					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">Easy scalability is a powerful feature of Amazon Aurora. Scalability in its actual definition refers to being able to get larger or smaller depending on the need. Amazon Aurora allows you to easily achieve this by scaling the database instance up or down and adding or removing read replicas. Scaling across regions brings additional resilience to your architectures and could boost your application performance due to geographic proximity. You can perform all of these scaling operations through the Aurora console. You can also automate instance and read scaling using lambda function or scripts based on the usage pattern you define. You can extend the automation by feeding your database usage data from Aurora enhanced monitoring into Machine Learning to provide more sophisticated predictive patterns to drive your automation. In this session we will do a deep dive into how scalability works in Aurora and how to make the best use of it to reduce your cost, increase application performance and architect resilient applications.

You should have good database knowledge and at least some experience with Amazon RDS or Amazon Aurora and should bring your own laptop.</span>


        <small class="length">2.5 hours</small>


        <small class="type">Workshop</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>


<div id="session_10493" class="resultRow sessionRow ">
    <div class="detailColumn">



        <a href="sessionDetail.ww?SESSION_ID=10493" class="openInPopup">

            <span class="abbreviation">DAT323 - </span>

            <span class="title">Workshop: Converting Your Oracle or Microsoft SQL Server Database to an Open Source Amazon Aurora or PostgreSQL Database Using AWS SCT and AWS DMS



					</span>
        </a>

        <label style="color:#0126f5;">Just Added!</label>


        <span class="abstract">In this workshop, you migrate a sample sporting event and ticketing database from Oracle or Microsoft SQL Server to Amazon Aurora or Postgre SQL using the AWS Schema Conversion Tool (AWS SCT) and AWS Database Migration Service (AWS DMS). The workshop includes the migration of tables, indexes, procedures, functions, constraints, views, and more. We run SCT on a Amazon EC2 Windows instance--bring a laptop with Remote Desktop (or some other method of connecting to the Windows instance). Ideally, you should be familiar with relational databases, especially Oracle or SQL Server and PostgreSQL or Aurora, to get the most from this session. Additionally, attendees should be familiar with SCT and DMS. Familiarity with SQL Developer and pgAdmin III will be helpful but is not required.

Prerequisites:


	Participants should have an AWS account established and available for use during the workshop.
	Please bring your own laptop.


&nbsp;</span>


        <small class="length">2.5 hours</small>


        <small class="type">Workshop</small>


        <span class="track"></span>
        <span class="scheduleStatus">




				</span>
    </div>
    <div class="actionColumn">







    </div>
</div>





<div id="downloadDocsDialog" title="Available Docs"></div>


<script type="text/javascript" charset="utf-8">

    //update search quantities
    updateSearchCount({
        attendee: '',
        session: '33',
        speaker: '',
        exhibitor: '',
        file: '0'
    });

    $(function(){
        sessionTooltip();
        downloadDocDialogInit();
        ratingInit();
    });
</script>
</a>